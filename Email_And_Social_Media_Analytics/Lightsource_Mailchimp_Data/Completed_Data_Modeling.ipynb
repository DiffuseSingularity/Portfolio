{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "secure_df = pd.read_csv(\"Complete_Secure_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "secure_df.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bounce Type</th>\n",
       "      <th>Hard Bounces</th>\n",
       "      <th>Member_Rating</th>\n",
       "      <th>Opens</th>\n",
       "      <th>Soft Bounces</th>\n",
       "      <th>Successful Deliveries</th>\n",
       "      <th>Total Bounces</th>\n",
       "      <th>Total Recipients</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>email_id</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sent</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1839.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1282</td>\n",
       "      <td>Register as a member before New Years to get y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sent</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1839.0</td>\n",
       "      <td>1</td>\n",
       "      <td>401</td>\n",
       "      <td>Register as a member before New Years to get y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sent</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1839.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1494</td>\n",
       "      <td>Register as a member before New Years to get y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sent</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1839.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1532</td>\n",
       "      <td>Register as a member before New Years to get y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sent</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1839.0</td>\n",
       "      <td>1</td>\n",
       "      <td>411</td>\n",
       "      <td>Register as a member before New Years to get y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Bounce Type  Hard Bounces  Member_Rating  Opens  Soft Bounces  \\\n",
       "0        sent          16.0            4.0    1.0          39.0   \n",
       "1        sent          16.0            2.0    1.0          39.0   \n",
       "2        sent          16.0            3.0    3.0          39.0   \n",
       "3        sent          16.0            2.0    1.0          39.0   \n",
       "4        sent          16.0            2.0    1.0          39.0   \n",
       "\n",
       "   Successful Deliveries  Total Bounces  Total Recipients  campaign_id  \\\n",
       "0                 1784.0           55.0            1839.0            1   \n",
       "1                 1784.0           55.0            1839.0            1   \n",
       "2                 1784.0           55.0            1839.0            1   \n",
       "3                 1784.0           55.0            1839.0            1   \n",
       "4                 1784.0           55.0            1839.0            1   \n",
       "\n",
       "   email_id                                            Subject  \n",
       "0      1282  Register as a member before New Years to get y...  \n",
       "1       401  Register as a member before New Years to get y...  \n",
       "2      1494  Register as a member before New Years to get y...  \n",
       "3      1532  Register as a member before New Years to get y...  \n",
       "4       411  Register as a member before New Years to get y...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secure_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11577, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secure_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's dummy the bounce type into a sent dummy\n",
    "secure_df['sent_dummy'] = [1 if i == 'sent' else 0 for i in secure_df['Bounce Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "secure_df.drop(\"Total Bounces\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "secure_df.drop(\"Bounce Type\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one is the combined value of Successful deliveries and bounces, thus unneccessary\n",
    "secure_df.drop('Total Recipients', axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = secure_df['Subject']\n",
    "y = secure_df['Opens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_machineCV(estimator, X, y, scoring = 'RMSE'):\n",
    "    X = secure_df['Subject']    \n",
    "    y = secure_df['Opens']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3)\n",
    "\n",
    "    \n",
    "    cv = CountVectorizer(max_features = 50, stop_words = stopwords.words('english'))\n",
    "    cv.fit(X_train)\n",
    "    X_train_scaled = cv.transform(X_train)\n",
    "    X_test_scaled = cv.transform(X_test)\n",
    "    estimators = [estimator] \n",
    "    for e in estimators:\n",
    "        est = e()\n",
    "        est.fit(X_train_scaled, y_train)\n",
    "        train_score = est.score(X_train_scaled, y_train)\n",
    "        r_sq = est.score(X_test_scaled, y_test)\n",
    "        preds= est.predict(X_test_scaled)\n",
    "        rmse= np.sqrt(mean_squared_error(y_test, preds))\n",
    "        print(train_score)\n",
    "    return [\"our R Squared is {} and our RMSE is {}\".format( r_sq, rmse)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005816235791066936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['our R Squared is 0.0008287453594035821 and our RMSE is 0.44683047874436443']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_machineCV(lr, secure_df['Subject'], secure_df['Opens'], scoring = 'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "global of,tf,rf,ov,tv,rv,os,ts,rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_machinetfidf(estimator, X, y, scoring = 'RMSE'):\n",
    "    X = secure_df['Subject']    \n",
    "    y = secure_df['Opens']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3)\n",
    "\n",
    "    \n",
    "    tfidf = TfidfVectorizer(max_features = 100, stop_words = stopwords.words('english'))\n",
    "    tfidf.fit(X_train)\n",
    "    X_train_scaled = tfidf.transform(X_train)\n",
    "    X_test_scaled = tfidf.transform(X_test)\n",
    "    estimators = [estimator] \n",
    "    for e in estimators:\n",
    "        est = e()\n",
    "        est.fit(X_train_scaled, y_train)\n",
    "        train_score = est.score(X_train_scaled, y_train)\n",
    "        r_sq = est.score(X_test_scaled, y_test)\n",
    "        preds= est.predict(X_test_scaled)\n",
    "        rmse= np.sqrt(mean_squared_error(y_test, preds))\n",
    "    return [\"our R Squared is {} and our RMSE is {}.  Our predictions are {}\".format( r_sq, rmse, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['our R Squared is 0.0034695695833167894 and our RMSE is 0.4801747358426549.  Our predictions are [0.11464968 0.1094196  0.16509434 ... 0.16509434 0.16509434 0.16509434]']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not promising! how's about a tfidf?  Slighly better but still not promising!\n",
    "# This does slightly better because it normalizes the count but is still not meaningful.\n",
    "regression_machinetfidf(lr, X, y, scoring = 'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about classification with NLP on whether an email is sent to one's inbox?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_machineCV(estimator, X, y, scoring = 'RMSE'):\n",
    "    X = secure_df['Subject']    \n",
    "    y = secure_df['sent_dummy']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state = 42)\n",
    "\n",
    "    \n",
    "    cv = CountVectorizer(max_features = 42420, stop_words = stopwords.words('english'))\n",
    "    cv.fit(X_train)\n",
    "    X_train_scaled = cv.transform(X_train)\n",
    "    X_test_scaled = cv.transform(X_test)\n",
    "    estimators = [estimator] \n",
    "    for e in estimators:\n",
    "        est = e()\n",
    "        est.fit(X_train_scaled, y_train)\n",
    "        train_score = est.score(X_train_scaled, y_train)\n",
    "        r_sq = est.score(X_test_scaled, y_test)\n",
    "        preds= est.predict(X_test_scaled)\n",
    "    \n",
    "    return [\"our training data has an r^2 of {} while our testing data has an r^2 of {}. Our predictions are {}\".format(train_score, r_sq, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['our training data has an r^2 of 0.9627470035633301 while our testing data has an r^2 of 0.9654576856649395. Our predictions are [1 1 1 ... 1 1 1]']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_machineCV(logr, secure_df['Subject'], secure_df['sent_dummy']\n",
    "                         , scoring = 'RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These above values don't mean a lot as is, because generally speaking, most of the emails do get sent at that rate.    A more complex model and more data is needed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_machineCV(estimator, X, y, scoring = 'RMSE'):\n",
    "    X = secure_df['Subject']    \n",
    "    y = secure_df['sent_dummy']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=.2, random_state = 42)\n",
    "\n",
    "    \n",
    "    tfidf = TfidfVectorizer(max_features = 32222, stop_words = stopwords.words('english'))\n",
    "    tfidf.fit(X_train)\n",
    "    X_train_scaled = tfidf.transform(X_train)\n",
    "    X_test_scaled = tfidf.transform(X_test)\n",
    "\n",
    "    estimators = [estimator] \n",
    "    for e in estimators:\n",
    "        est = e()\n",
    "        est.fit(X_train_scaled, y_train)\n",
    "        train_score = est.score(X_train_scaled, y_train)\n",
    "        r_sq = est.score(X_test_scaled, y_test)\n",
    "        preds= est.predict(X_test_scaled)\n",
    "        print(preds)\n",
    "    return [\"our training data has an r^2 of {} while our testing data has an r^2 of {}. Our predictions are {}\".format(train_score, r_sq, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['our training data has an r^2 of 0.9627470035633301 while our testing data has an r^2 of 0.9654576856649395. Our predictions are [1 1 1 ... 1 1 1]']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_machineCV(logr, X, y, scoring = 'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['our training data has an r^2 of 0.9627470035633301 while our testing data has an r^2 of 0.9654576856649395. Our predictions are [1 1 1 ... 1 1 1]']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_machineCV(mlb, X, y, scoring = 'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['our training data has an r^2 of 0.9627470035633301 while our testing data has an r^2 of 0.9654576856649395. Our predictions are [1 1 1 ... 1 1 1]']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_machineCV(rfc, X, y, scoring = 'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-ded5ba42480f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
