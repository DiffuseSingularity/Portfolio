{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "try:\n",
    "    from urllib.request import urlopen, Request\n",
    "except ImportError:\n",
    "    from urllib2 import urlopen, Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access tokens for pages https://developers.facebook.com/docs/facebook-login/access-tokens/#pagetokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blog post related to scraper https://minimaxir.com/2015/07/facebook-scraper/  \n",
    "# and https://medium.com/@DrGabrielA81/python-how-making-facebook-api-calls-using-facebook-sdk-ea18bec973c8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph API documentation https://developers.facebook.com/docs/graph-api \n",
    "# Graph API FAQhttps://developers.facebook.com/docs/graph-api/faq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_id = \"353798235493082\"\n",
    "app_secret = \"60dff8b523310aa8467b79a7c709167a\"  # DO NOT SHARE WITH ANYONE!\n",
    "page_id = \"LightSourceUniverse\"\n",
    "\n",
    "# input date formatted as YYYY-MM-DD\n",
    "since_date = \"2016-01-01\"\n",
    "until_date = \"2019-05-07\"\n",
    "\n",
    "access_token = app_id + \"|\" + app_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_until_succeed(url):\n",
    "    req = Request(url)\n",
    "    success = False\n",
    "    while success is False:\n",
    "        try:\n",
    "            response = urlopen(req)\n",
    "            if response.getcode() == 200:\n",
    "                success = True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(5)\n",
    "\n",
    "            print(\"Error for URL {}: {}\".format(url, datetime.datetime.now()))\n",
    "            print(\"Retrying.\")\n",
    "\n",
    "    return response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Needed to write tricky unicode correctly to csv\n",
    "def unicode_decode(text):\n",
    "    try:\n",
    "        return text.encode('utf-8').decode()\n",
    "    except UnicodeDecodeError:\n",
    "        return text.encode('utf-8')\n",
    "\n",
    "\n",
    "def getFacebookPageFeedUrl(base_url):\n",
    "\n",
    "    # Construct the URL string; see http://stackoverflow.com/a/37239851 for\n",
    "    # Reactions parameters\n",
    "    fields = \"&fields=message,link,created_time,type,name,id,\" + \\\n",
    "        \"comments.limit(0).summary(true),shares,reactions\" + \\\n",
    "        \".limit(0).summary(true)\"\n",
    "\n",
    "    return base_url + fields\n",
    "\n",
    "\n",
    "def getReactionsForStatuses(base_url):\n",
    "\n",
    "    reaction_types = ['like', 'love', 'wow', 'haha', 'sad', 'angry']\n",
    "    reactions_dict = {}   # dict of {status_id: tuple<6>}\n",
    "\n",
    "    for reaction_type in reaction_types:\n",
    "        fields = \"&fields=reactions.type({}).limit(0).summary(total_count)\".format(\n",
    "            reaction_type.upper())\n",
    "\n",
    "        url = base_url + fields\n",
    "\n",
    "        data = json.loads(request_until_succeed(url))['data']\n",
    "\n",
    "        data_processed = set()  # set() removes rare duplicates in statuses\n",
    "        for status in data:\n",
    "            id = status['id']\n",
    "            count = status['reactions']['summary']['total_count']\n",
    "            data_processed.add((id, count))\n",
    "\n",
    "        for id, count in data_processed:\n",
    "            if id in reactions_dict:\n",
    "                reactions_dict[id] = reactions_dict[id] + (count,)\n",
    "            else:\n",
    "                reactions_dict[id] = (count,)\n",
    "\n",
    "    return reactions_dict\n",
    "\n",
    "\n",
    "def processFacebookPageFeedStatus(status):\n",
    "\n",
    "    # The status is now a Python dictionary, so for top-level items,\n",
    "    # we can simply call the key.\n",
    "\n",
    "    # Additionally, some items may not always exist,\n",
    "    # so must check for existence first\n",
    "\n",
    "    status_id = status['id']\n",
    "    status_type = status['type']\n",
    "\n",
    "    status_message = '' if 'message' not in status else \\\n",
    "        unicode_decode(status['message'])\n",
    "    link_name = '' if 'name' not in status else \\\n",
    "        unicode_decode(status['name'])\n",
    "    status_link = '' if 'link' not in status else \\\n",
    "        unicode_decode(status['link'])\n",
    "\n",
    "    # Time needs special care since a) it's in UTC and\n",
    "    # b) it's not easy to use in statistical programs.\n",
    "\n",
    "    status_published = datetime.datetime.strptime(\n",
    "        status['created_time'], '%Y-%m-%dT%H:%M:%S+0000')\n",
    "    status_published = status_published + \\\n",
    "        datetime.timedelta(hours=-5)  # EST\n",
    "    status_published = status_published.strftime(\n",
    "        '%Y-%m-%d %H:%M:%S')  # best time format for spreadsheet programs\n",
    "\n",
    "    # Nested items require chaining dictionary keys.\n",
    "\n",
    "    num_reactions = 0 if 'reactions' not in status else \\\n",
    "        status['reactions']['summary']['total_count']\n",
    "    num_comments = 0 if 'comments' not in status else \\\n",
    "        status['comments']['summary']['total_count']\n",
    "    num_shares = 0 if 'shares' not in status else status['shares']['count']\n",
    "\n",
    "    return (status_id, status_message, link_name, status_type, status_link,\n",
    "            status_published, num_reactions, num_comments, num_shares)\n",
    "\n",
    "\n",
    "def scrapeFacebookPageFeedStatus(page_id, access_token, since_date, until_date):\n",
    "    with open('{}_facebook_statuses.csv'.format(page_id), 'w') as file:\n",
    "        w = csv.writer(file)\n",
    "        w.writerow([\"status_id\", \"status_message\", \"link_name\", \"status_type\",\n",
    "                    \"status_link\", \"status_published\", \"num_reactions\",\n",
    "                    \"num_comments\", \"num_shares\", \"num_likes\", \"num_loves\",\n",
    "                    \"num_wows\", \"num_hahas\", \"num_sads\", \"num_angrys\",\n",
    "                    \"num_special\"])\n",
    "\n",
    "        has_next_page = True\n",
    "        num_processed = 0\n",
    "        scrape_starttime = datetime.datetime.now()\n",
    "        after = ''\n",
    "        base = \"https://graph.facebook.com/v2.9\"\n",
    "        node = \"/{}/posts\".format(page_id)\n",
    "        parameters = \"/?limit={}&access_token={}\".format(100, access_token)\n",
    "        since = \"&since={}\".format(since_date) if since_date \\\n",
    "            is not '' else ''\n",
    "        until = \"&until={}\".format(until_date) if until_date \\\n",
    "            is not '' else ''\n",
    "\n",
    "        print(\"Scraping {} Facebook Page: {}\\n\".format(page_id, scrape_starttime))\n",
    "\n",
    "        while has_next_page:\n",
    "            after = '' if after is '' else \"&after={}\".format(after)\n",
    "            base_url = base + node + parameters + after + since + until\n",
    "\n",
    "            url = getFacebookPageFeedUrl(base_url)\n",
    "            statuses = json.loads(request_until_succeed(url))\n",
    "            reactions = getReactionsForStatuses(base_url)\n",
    "\n",
    "            for status in statuses['data']:\n",
    "\n",
    "                # Ensure it is a status with the expected metadata\n",
    "                if 'reactions' in status:\n",
    "                    status_data = processFacebookPageFeedStatus(status)\n",
    "                    reactions_data = reactions[status_data[0]]\n",
    "\n",
    "                    # calculate thankful/pride through algebra\n",
    "                    num_special = status_data[6] - sum(reactions_data)\n",
    "                    w.writerow(status_data + reactions_data + (num_special,))\n",
    "\n",
    "                num_processed += 1\n",
    "                if num_processed % 100 == 0:\n",
    "                    print(\"{} Statuses Processed: {}\".format\n",
    "                          (num_processed, datetime.datetime.now()))\n",
    "\n",
    "            # if there is no next page, we're done.\n",
    "            if 'paging' in statuses:\n",
    "                after = statuses['paging']['cursors']['after']\n",
    "            else:\n",
    "                has_next_page = False\n",
    "\n",
    "        print(\"\\nDone!\\n{} Statuses Processed in {}\".format(\n",
    "              num_processed, datetime.datetime.now() - scrape_starttime))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    scrapeFacebookPageFeedStatus(page_id, access_token, since_date, until_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
