{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Correlated Data Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated States\n",
    "\n",
    "Read [this](http://fivethirtyeight.com/features/why-fivethirtyeight-gave-trump-a-better-chance-than-almost-anyone-else/) FiveThirtyEight article about 2016 polling.\n",
    "\n",
    "Suppose you were advising a Presidential candidate's pollster in the 2020 election. \n",
    "\n",
    "The pollster took polls in every state/region with electoral votes, treated each state as \"independent coin flips,\" and estimated the probability of your candidate winning by simulating 1,000,000 elections. (This is an example of [Monte Carlo simulations](http://www.palisade.com/risk/monte_carlo_simulation.asp)!)\n",
    "\n",
    "**Question:** What suggestions do you have for the pollster? Specifically, discuss how appropriate the assumption of independence is in this case and suggest improvements if you feel any are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** Spatial and temporal data are especially highly correlated - it is not at all reasonable to treat this data as independent at each point, because it is not.\n",
    "\n",
    "You can look at previous polling errors in prior election cycles, and get a better idea of the expected variance between predicted and actual election results with those.  The most obvious pattern from the prior 2016 presidential election cycles, is that multiple states polling choices and polling errors were correlated, particularly between those that are geographically close to one another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Stock Prices\n",
    "\n",
    "You're interested in the performance of a particular stock. You use the [autocorrelation function](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.autocorr.html) in Pandas to assess how autocorrelated your stock's values are.\n",
    "\n",
    "Autocorrelation makes explicit the idea of temporal correlation we discussed previously. Suppose we wanted to see how correlated a stock's prices are with the immediately preceding day's stock prices. \n",
    "\n",
    "| Day | Price | Price with Lag = 1 | Price with Lag = 2 |\n",
    "|-----|-------|--------------------|--------------------|\n",
    "| 1   | 25    | NA                 | NA                 |\n",
    "| 2   | 26    | 25                 | NA                 |\n",
    "| 3   | 28    | 26                 | 25                 |\n",
    "| 4   | 24    | 28                 | 26                 |\n",
    "| 5   | 23    | 24                 | 28                 |\n",
    "\n",
    "Autocorrelation with a lag of 1 will calculate the correlation between column \"Price\" and column \"Price with Lag = 1.\" Autocorrelation with a lag of $k$ will calculate the correlation between stock price and the stock price of $k$ days before in a similar manner.\n",
    "\n",
    "I build a loop that iterates through days (we'll assume our stock price is the closing price at every day) 1 to 365 to assess how correlated a stock price is with the stock price from $i$ days ago. (Sample code seen below.)\n",
    "\n",
    "```\n",
    "for i in range(1, 366):\n",
    "    print(df[stock_prices].autocorr(lag=i))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Suppose my highest values of autocorrelation are found when $i = 1, 7, 30, 365$. What do each of these suggest about the performance of this particular stock?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** The stock performance is most strongly correlated with itself in intervals of a day, week, month, and year apart from any particular day of performance.  When it is not at those values of i, it's correlation weakens, meaning it varies in value more on other days (values of i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stock prices vary quite rapidly. Looking at almost any plot of stock price over time, we'll see a very \"wiggly\" function that moves around erratically. Building a model for this can be difficult.\n",
    "\n",
    "One way to \"de-noise\" or \"smooth\" this is to create a [moving average](http://www.investopedia.com/terms/m/movingaverage.asp) of stock prices. Suppose I wanted to create a moving average of stock prices across $k$ days. In this case, I create a new column that takes the current day and $k-1$ previous days (for $k$ total days) and average the stock prices of these days.\n",
    "\n",
    "For example, I have a column of stock prices and a column associated with a moving average for three days. Then, my row for Day 5 includes the Day 5 stock price and the average of Day 3, Day 4, and Day 5 stock prices. (We'll go more in detail with this later.)\n",
    "\n",
    "| Day | Price | Moving Average k = 3 |\n",
    "|-----|-------|----------------------|\n",
    "| 1   | 25    | NA                   |\n",
    "| 2   | 26    | NA                   |\n",
    "| 3   | 28    | 26.33                |\n",
    "| 4   | 24    | 26                   |\n",
    "| 5   | 23    | 25                   |\n",
    "\n",
    "**Question:** As the number of periods $k$ increases, how do I expect my plotted curve to change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** it will be much smoother - there will be less fluctuation in the line - as the number of periods used to calculate the moving average increases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Suppose we use our moving average to predict values of the stock price. As $k$ increases, how is the bias of our predictions affected? As $k$ increases, how is the variance of our predictions affected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Our variance moves down, and our bias goes up, as k increases.  The moving average simplifies the model.  Smoothing over day to day fluctuations by using a higher k value may make the model better generalize to new predictions, but it can also make it too simple.  As we know, too much of either can cause model inaccuracy on new testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
