{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Lab\n",
    "\n",
    "> Author: Matt Brems (DC)\n",
    "\n",
    "In this lab, we are going to find out why neural networks are so good at what they do. Specifically, we'll do three things:\n",
    "1. Build and plot a \"complicated, wiggly\" function. This function could resemble any complicated real-world process that we would like to be able to model.\n",
    "2. Build a neural network from scratch that very closely approximates this function. (That is, the predicted values from the neural network are very, very close to the true values from the \"real\" function.)\n",
    "3. Understand the reason why neural networks are great, called the _Universal Approximation Theorem_.\n",
    "\n",
    "**Optional Video**: If you want a visual refresher on neural networks and their building blocks, head to [this link](https://www.youtube.com/watch?v=aircAruvnKk) and watch the 3Blue1Brown video on \"But what *is* a Neural Network?\" It's a **phenomenal** 20-minute introduction to solidify the building blocks of a neural network. (This is optional, but probably worth your time!)\n",
    "\n",
    "**Required Reading**: Head over to [this site](http://neuralnetworksanddeeplearning.com/chap4.html) and read from the beginning of the page until the \"Many Input Variables\" section.\n",
    "\n",
    "#### Recommended Order of Reading\n",
    "The introduction and the \"Two Caveats\" section are pretty mathematical in nature. I think this is a great resource, but wish that the author didn't start off with a mathematical theorem. If I were reading this page, I would:\n",
    "- skim the introduction,\n",
    "- skip the \"Two Caveats\" section,\n",
    "- read the \"Universality with One Input and One Output\" section,\n",
    "- go back and read the introduction,\n",
    "- then go back and read the \"Two Caveats\" section.\n",
    "\n",
    "(You do not need to read the \"Many Input Variables\" section and beyond but are certainly welcome to do so!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1:** Examine the image below. This shows a small neural network.\n",
    "\n",
    "<img src=\"./images/weight_bias.jpg\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "In this image:\n",
    "- How many input nodes are there? \n",
    "- How many hidden nodes are there?\n",
    "- How many hidden layers are there?\n",
    "- How many output nodes are there?\n",
    "- What does $w$ mean? \n",
    "- While only one is explicitly drawn on the diagram, how many values of $w$ would we expect in this neural network?\n",
    "- What does $b$ mean? \n",
    "- While only one is explicitly drawn on the diagram, how many values of $b$ would we expect in this neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "- How many input nodes are there? 1\n",
    "- How many hidden nodes are there? 2\n",
    "- How many hidden layers are there? 1\n",
    "- How many output nodes are there? 1\n",
    "- What does $w$ mean? weight\n",
    "- While only one is explicitly drawn on the diagram, how many values of $w$ would we expect in this neural network? 4\n",
    "- What does $b$ mean? beta or the intercept\n",
    "- While only one is explicitly drawn on the diagram, how many values of $b$ would we expect in this neural network? 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2:** For a sigmoidal activation function to closely resemble a step function, how would you describe the values of $w$ and $b$?\n",
    "\n",
    "_Hint:_ Try playing around with the applets on the page to test how different parts of the perceptron affect the output.\n",
    "\n",
    "_Note:_ In an attempt to make things easier, the article defines $s = \\frac{−b}{w}$. The author's goal is to only describe one parameter $s$ instead of describing $b$ and $w$. I find this notation confusing, because that notation only applies to this article and isn't used elsewhere. I'm going to stick with $b$ and $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** the absolute value of w must be above 30(below -30 alternatively) and b/w must be lower than -.03 to roughly approximate a step function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3**: \n",
    "The author asks you to find values of $h_i$ that make your neural network closely approximate $f(x)$. Record your values of $h_i$ here and your best \"average deviation\" score.\n",
    "- Note $h$ is simply a weight. The author is calling it $h$ to correpond to height, but it's just a weight corresponding to the connection between the hidden layer and the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** \n",
    "<br>\n",
    "h1: -1.2\n",
    "<br>\n",
    "h2: -1.4\n",
    "<br>\n",
    "h3: -0.4\n",
    "<br>\n",
    "h4: -1.0\n",
    "<br>\n",
    "h5: 1.2\n",
    "Average deviation: 0.38 (Success!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 4**: Build the neural network from your work in Problem 3 here.\n",
    "\n",
    "A few things to keep in mind:\n",
    "- How many inputs are there? \n",
    "- How many outputs are there?\n",
    "- How many neurons are in the hidden layer? \n",
    "- In order to create a step function at a specific value of $x$:\n",
    "    - what should the value of $w$ be?\n",
    "    - what should the value of $b$ be?\n",
    "    - use a [sigmoid activation function](https://en.wikipedia.org/wiki/Activation_function#Comparison_of_activation_functions).\n",
    "- What do the values of $h_i$ represent?\n",
    "- Use an [sigmoid activation function](https://en.wikipedia.org/wiki/Activation_function#Comparison_of_activation_functions) on the last layer.\n",
    "\n",
    "The values of $h$ on this diagram are **not correct**, but this image may be helpful to you as you plan out your network!\n",
    "\n",
    "<img src=\"./images/network.jpg\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sigmoid activation function.\n",
    "def sigmoid_activation(x):\n",
    "    sig = (1/(1+np.exp(-x)))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10998cc50>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot your activation function so that it looks correct.\n",
    "z = np.linspace(-10,100,1000)\n",
    "plt.plot(sigmoid_activation(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will take in your weight (w)\n",
    "# and where you want the step to occur, then solve for\n",
    "# the bias.\n",
    "\n",
    "def solve_for_bias(s, w = 500):\n",
    "    bias = -s*w\n",
    "    return bias\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model structure (topology) and define the weights and biases.\n",
    "\n",
    "\n",
    "# Specify weights and biases from input to hidden layer.   #Thanks for the help with this Noah Christiansen!\n",
    "steps = np.array([0, .2, .2, .4, .4, .6, .6, .8, .8, 1])\n",
    "weights_hidden = np.array([500]*10)\n",
    "#bias_hidden = [solve_for_bias(s, w) for s, w in zip(steps, weights_hidden)]\n",
    "bias_hidden = solve_for_bias(steps)\n",
    "bias_output = 0\n",
    "\n",
    "# Remember: what are our values of weights from the hidden layer to the output layer?\n",
    "\n",
    "# These are the values of h that we got!\n",
    "weights_output = np.array([-1.2, -1.4, -0.4, -1.0, 1.2, 1.2, 1.4, 0.4, 1.0, -1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to run the network:\n",
    "def run_network(x):\n",
    "    \n",
    "    # Define your input value. This should just be one value.\n",
    "    input_value = x\n",
    "    \n",
    "    # Calculate the value of the nodes in the hidden layer.\n",
    "    Z_hidden = input_value*weights_hidden + bias_hidden\n",
    "    \n",
    "    # Use your activation function to transform the value of your nodes.\n",
    "    activation_hidden = np.array([sigmoid_activation(Z) for Z in Z_hidden])\n",
    "\n",
    "    # Calculate the value of the nodes in the output layer.\n",
    "    Z_output = np.sum(activation_hidden * weights_output) + bias_output\n",
    "    \n",
    "    # Use your activation function to transform the value of your output node.\n",
    "    activation_output = sigmoid_activation(Z_output)\n",
    "    \n",
    "    # Return the output of your network!\n",
    "    return activation_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5**: Now that we've built our neural network, let's evaluate the performance of it!\n",
    "\n",
    "\n",
    "- Use `np.linspace` to generate 1000 values of $x$ between 0 and 1. \n",
    "- Your $y$ values are the actual observed values of $f(x)=0.2+0.4x^2+0.3x\\sin(15x)+0.05\\cos(50x)$ for each of the $x$ that you generated using `np.linspace`. Generate $y$ (using the true function $f(x))$ for all values of $x$.\n",
    "- Your $\\hat{y}$ in this case are your predicted values from your neural network for each of the $x$ that you generated using `np.linspace`.\n",
    "- Visually compare $y$ and $\\hat{y}$ by plotting both on one grid.\n",
    "- Compare $y$ and $\\hat{y}$ using mean squared error.\n",
    "\n",
    "Recall that mean squared error is given by:\n",
    "\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{i=1}^n (\\hat{y}-y)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35434369377420455,\n",
       " 0.3214551968987982,\n",
       " 0.2936947783385622,\n",
       " 0.2726224147245267,\n",
       " 0.2578432679684694,\n",
       " 0.2480237035545803,\n",
       " 0.2417238764881266,\n",
       " 0.2377699599812469,\n",
       " 0.23532178241802384,\n",
       " 0.23381843505062935,\n",
       " 0.23289992591767789,\n",
       " 0.23234045813064572,\n",
       " 0.2320003181583388,\n",
       " 0.23179375665545662,\n",
       " 0.23166840116351073,\n",
       " 0.23159235859131783,\n",
       " 0.2315462416219647,\n",
       " 0.23151827768289568,\n",
       " 0.23150132276482174,\n",
       " 0.23149104334392598,\n",
       " 0.2314848113529959,\n",
       " 0.2314810332307103,\n",
       " 0.23147874278620914,\n",
       " 0.23147735424030907,\n",
       " 0.23147651246010134,\n",
       " 0.23147600214788022,\n",
       " 0.23147569278194316,\n",
       " 0.23147550523561172,\n",
       " 0.2314753915398219,\n",
       " 0.23147532261430534,\n",
       " 0.23147528082977,\n",
       " 0.2314752554988442,\n",
       " 0.23147524014254683,\n",
       " 0.23147523083314137,\n",
       " 0.23147522518952668,\n",
       " 0.23147522176821403,\n",
       " 0.23147521969412127,\n",
       " 0.23147521843674995,\n",
       " 0.2314752176744973,\n",
       " 0.23147521721239897,\n",
       " 0.2314752169322625,\n",
       " 0.23147521676243607,\n",
       " 0.23147521665948267,\n",
       " 0.23147521659706963,\n",
       " 0.23147521655923303,\n",
       " 0.23147521653629552,\n",
       " 0.23147521652239011,\n",
       " 0.23147521651396036,\n",
       " 0.23147521650884992,\n",
       " 0.23147521650575187,\n",
       " 0.2314752165038738,\n",
       " 0.23147521650273528,\n",
       " 0.23147521650204503,\n",
       " 0.23147521650162659,\n",
       " 0.2314752165013729,\n",
       " 0.23147521650121913,\n",
       " 0.2314752165011259,\n",
       " 0.23147521650106936,\n",
       " 0.23147521650103514,\n",
       " 0.23147521650101435,\n",
       " 0.23147521650100178,\n",
       " 0.23147521650099412,\n",
       " 0.2314752165009895,\n",
       " 0.23147521650098665,\n",
       " 0.23147521650098493,\n",
       " 0.23147521650098393,\n",
       " 0.23147521650098332,\n",
       " 0.23147521650098293,\n",
       " 0.23147521650098266,\n",
       " 0.2314752165009826,\n",
       " 0.23147521650098252,\n",
       " 0.23147521650098246,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098238,\n",
       " 0.23147521650098232,\n",
       " 0.23147521650098232,\n",
       " 0.23147521650098227,\n",
       " 0.23147521650098218,\n",
       " 0.23147521650098218,\n",
       " 0.231475216500982,\n",
       " 0.2314752165009818,\n",
       " 0.2314752165009814,\n",
       " 0.23147521650098074,\n",
       " 0.2314752165009797,\n",
       " 0.23147521650097808,\n",
       " 0.23147521650097524,\n",
       " 0.23147521650097058,\n",
       " 0.23147521650096287,\n",
       " 0.2314752165009502,\n",
       " 0.23147521650092936,\n",
       " 0.2314752165008949,\n",
       " 0.23147521650083808,\n",
       " 0.23147521650074443,\n",
       " 0.23147521650058986,\n",
       " 0.23147521650033487,\n",
       " 0.2314752164999143,\n",
       " 0.23147521649922062,\n",
       " 0.23147521649807629,\n",
       " 0.2314752164961886,\n",
       " 0.23147521649307484,\n",
       " 0.23147521648793853,\n",
       " 0.2314752164794658,\n",
       " 0.2314752164654899,\n",
       " 0.23147521644243593,\n",
       " 0.2314752164044073,\n",
       " 0.23147521634167723,\n",
       " 0.23147521623820108,\n",
       " 0.23147521606751242,\n",
       " 0.2314752157859535,\n",
       " 0.2314752153215089,\n",
       " 0.23147521455538583,\n",
       " 0.23147521329163007,\n",
       " 0.2314752112070061,\n",
       " 0.23147520776832156,\n",
       " 0.23147520209605127,\n",
       " 0.23147519273937742,\n",
       " 0.231475177305109,\n",
       " 0.23147515184556794,\n",
       " 0.23147510984887992,\n",
       " 0.2314750405734191,\n",
       " 0.23147492630041108,\n",
       " 0.2314747378020164,\n",
       " 0.23147442686583788,\n",
       " 0.23147391396405956,\n",
       " 0.23147306791396885,\n",
       " 0.23147167232935714,\n",
       " 0.23146937028685077,\n",
       " 0.2314655730676099,\n",
       " 0.23145930966921419,\n",
       " 0.23144897869557318,\n",
       " 0.23143193943342738,\n",
       " 0.23140383825404126,\n",
       " 0.23135750003717834,\n",
       " 0.2312811064678674,\n",
       " 0.23115520990473387,\n",
       " 0.23094785871987203,\n",
       " 0.23060669449949475,\n",
       " 0.2300462881059692,\n",
       " 0.2291282451365819,\n",
       " 0.22763102085779868,\n",
       " 0.22520695877370922,\n",
       " 0.22132859562847174,\n",
       " 0.21524098076579556,\n",
       " 0.20597151843622744,\n",
       " 0.19250603734589639,\n",
       " 0.17426901270818998,\n",
       " 0.15187661032789235,\n",
       " 0.127617656747183,\n",
       " 0.10479867860872241,\n",
       " 0.08608293286998052,\n",
       " 0.07237011050389217,\n",
       " 0.06308935844824731,\n",
       " 0.05710877284123907,\n",
       " 0.05336027618539463,\n",
       " 0.05104581223201549,\n",
       " 0.049628247071598894,\n",
       " 0.04876382002763424,\n",
       " 0.04823798513220261,\n",
       " 0.04791856496701328,\n",
       " 0.04772469033796416,\n",
       " 0.04760707327638486,\n",
       " 0.047535739562592605,\n",
       " 0.04749248375460882,\n",
       " 0.04746625673814922,\n",
       " 0.047450355677577695,\n",
       " 0.04744071546058576,\n",
       " 0.04743487109267718,\n",
       " 0.047431328002219234,\n",
       " 0.04742918005665518,\n",
       " 0.047427877903458614,\n",
       " 0.0474270884990514,\n",
       " 0.04742660993927086,\n",
       " 0.04742631982282264,\n",
       " 0.047426143946163325,\n",
       " 0.04742603732488584,\n",
       " 0.047425972688145614,\n",
       " 0.04742593350358843,\n",
       " 0.04742590974884196,\n",
       " 0.04742589534806805,\n",
       " 0.04742588661792721,\n",
       " 0.04742588132547852,\n",
       " 0.04742587811705226,\n",
       " 0.04742587617201709,\n",
       " 0.04742587499288392,\n",
       " 0.04742587427806135,\n",
       " 0.047425873844716485,\n",
       " 0.04742587358201107,\n",
       " 0.047425873422751896,\n",
       " 0.04742587332620465,\n",
       " 0.047425873267675105,\n",
       " 0.04742587323219291,\n",
       " 0.04742587321068263,\n",
       " 0.047425873197642514,\n",
       " 0.04742587318973723,\n",
       " 0.04742587318494483,\n",
       " 0.04742587318203959,\n",
       " 0.0474258731802783,\n",
       " 0.04742587317921058,\n",
       " 0.0474258731785633,\n",
       " 0.0474258731781709,\n",
       " 0.04742587317793302,\n",
       " 0.04742587317778879,\n",
       " 0.0474258731777014,\n",
       " 0.047425873177648396,\n",
       " 0.04742587317761625,\n",
       " 0.04742587317759678,\n",
       " 0.04742587317758496,\n",
       " 0.04742587317757779,\n",
       " 0.04742587317757346,\n",
       " 0.04742587317757083,\n",
       " 0.047425873177569224,\n",
       " 0.047425873177568266,\n",
       " 0.04742587317756768,\n",
       " 0.04742587317756732,\n",
       " 0.0474258731775671,\n",
       " 0.04742587317756698,\n",
       " 0.0474258731775669,\n",
       " 0.04742587317756686,\n",
       " 0.04742587317756682,\n",
       " 0.04742587317756682,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.04742587317756678,\n",
       " 0.04742587317756678,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.0474258731775668,\n",
       " 0.04742587317756682,\n",
       " 0.047425873177566844,\n",
       " 0.047425873177566885,\n",
       " 0.04742587317756693,\n",
       " 0.04742587317756702,\n",
       " 0.04742587317756716,\n",
       " 0.047425873177567406,\n",
       " 0.0474258731775678,\n",
       " 0.04742587317756844,\n",
       " 0.04742587317756953,\n",
       " 0.0474258731775713,\n",
       " 0.047425873177574206,\n",
       " 0.047425873177579035,\n",
       " 0.04742587317758698,\n",
       " 0.0474258731776001,\n",
       " 0.04742587317762173,\n",
       " 0.047425873177657445,\n",
       " 0.047425873177716286,\n",
       " 0.04742587317781341,\n",
       " 0.04742587317797361,\n",
       " 0.04742587317823785,\n",
       " 0.04742587317867371,\n",
       " 0.04742587317939273,\n",
       " 0.04742587318057874,\n",
       " 0.04742587318253513,\n",
       " 0.047425873185762316,\n",
       " 0.04742587319108569,\n",
       " 0.04742587319986683,\n",
       " 0.04742587321435175,\n",
       " 0.04742587323824531,\n",
       " 0.04742587327765883,\n",
       " 0.047425873342673286,\n",
       " 0.04742587344991764,\n",
       " 0.04742587362682224,\n",
       " 0.0474258739186346,\n",
       " 0.04742587439999264,\n",
       " 0.047425875194015116,\n",
       " 0.04742587650379195,\n",
       " 0.047425878664329194,\n",
       " 0.04742588222823416,\n",
       " 0.04742588810705611,\n",
       " 0.047425897804432036,\n",
       " 0.04742591380066475,\n",
       " 0.04742594018708449,\n",
       " 0.04742598371240881,\n",
       " 0.04742605550862889,\n",
       " 0.04742617393757639,\n",
       " 0.047426369285481336,\n",
       " 0.04742669150417784,\n",
       " 0.04742722297327741,\n",
       " 0.047428099532094106,\n",
       " 0.04742954511874164,\n",
       " 0.0474319287620429,\n",
       " 0.047435858193343575,\n",
       " 0.04744233318106241,\n",
       " 0.04745299553189434,\n",
       " 0.047470533566789444,\n",
       " 0.04749932807429228,\n",
       " 0.04754646126740448,\n",
       " 0.04762323260785616,\n",
       " 0.0477472785378261,\n",
       " 0.0479451308555878,\n",
       " 0.04825427369475359,\n",
       " 0.048722094786114445,\n",
       " 0.049396814275309016,\n",
       " 0.05030534654936096,\n",
       " 0.05142174340190179,\n",
       " 0.052648956783703245,\n",
       " 0.053843241191143004,\n",
       " 0.05487536319250795,\n",
       " 0.05567976060409852,\n",
       " 0.05625768088712464,\n",
       " 0.05664906850152481,\n",
       " 0.05690364425511223,\n",
       " 0.057064913259891686,\n",
       " 0.057165370740570945,\n",
       " 0.05722729366127629,\n",
       " 0.057265216699860795,\n",
       " 0.05728834945366797,\n",
       " 0.0573024260297323,\n",
       " 0.05731097915356249,\n",
       " 0.057316171483900634,\n",
       " 0.05731932186409842,\n",
       " 0.05732123268451314,\n",
       " 0.05732239143406914,\n",
       " 0.05732309403126226,\n",
       " 0.05732352001319251,\n",
       " 0.05732377827281017,\n",
       " 0.0573239348433484,\n",
       " 0.057324029763066504,\n",
       " 0.05732408730686192,\n",
       " 0.05732412219179875,\n",
       " 0.05732414334011451,\n",
       " 0.05732415616084195,\n",
       " 0.05732416393313131,\n",
       " 0.057324168644910224,\n",
       " 0.057324171501320784,\n",
       " 0.057324173232955224,\n",
       " 0.057324174282719395,\n",
       " 0.05732417491911504,\n",
       " 0.05732417530491541,\n",
       " 0.05732417553879809,\n",
       " 0.05732417568058412,\n",
       " 0.05732417576653869,\n",
       " 0.057324175818646676,\n",
       " 0.05732417585023594,\n",
       " 0.05732417586938623,\n",
       " 0.05732417588099565,\n",
       " 0.0573241758880336,\n",
       " 0.05732417589230019,\n",
       " 0.05732417589488672,\n",
       " 0.05732417589645472,\n",
       " 0.05732417589740533,\n",
       " 0.05732417589798159,\n",
       " 0.05732417589833092,\n",
       " 0.05732417589854272,\n",
       " 0.057324175898671115,\n",
       " 0.057324175898748914,\n",
       " 0.05732417589879614,\n",
       " 0.057324175898824714,\n",
       " 0.057324175898842075,\n",
       " 0.05732417589885258,\n",
       " 0.05732417589885897,\n",
       " 0.05732417589886281,\n",
       " 0.057324175898865154,\n",
       " 0.05732417589886657,\n",
       " 0.05732417589886746,\n",
       " 0.057324175898867936,\n",
       " 0.057324175898868276,\n",
       " 0.05732417589886847,\n",
       " 0.05732417589886857,\n",
       " 0.05732417589886866,\n",
       " 0.05732417589886871,\n",
       " 0.05732417589886871,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.057324175898868755,\n",
       " 0.0573241758988688,\n",
       " 0.0573241758988688,\n",
       " 0.0573241758988688,\n",
       " 0.05732417589886886,\n",
       " 0.05732417589886888,\n",
       " 0.05732417589886895,\n",
       " 0.05732417589886909,\n",
       " 0.05732417589886929,\n",
       " 0.057324175898869616,\n",
       " 0.05732417589887018,\n",
       " 0.05732417589887111,\n",
       " 0.05732417589887259,\n",
       " 0.05732417589887509,\n",
       " 0.057324175898879226,\n",
       " 0.057324175898885985,\n",
       " 0.05732417589889717,\n",
       " 0.05732417589891565,\n",
       " 0.05732417589894607,\n",
       " 0.057324175898996334,\n",
       " 0.05732417589907917,\n",
       " 0.05732417589921583,\n",
       " 0.05732417589944124,\n",
       " 0.05732417589981312,\n",
       " 0.057324175900426516,\n",
       " 0.05732417590143834,\n",
       " 0.0573241759031074,\n",
       " 0.05732417590586059,\n",
       " 0.05732417591040213,\n",
       " 0.057324175917893586,\n",
       " 0.05732417593025109,\n",
       " 0.05732417595063537,\n",
       " 0.057324175984260185,\n",
       " 0.057324176039725915,\n",
       " 0.057324176131219186,\n",
       " 0.05732417628214164,\n",
       " 0.05732417653109524,\n",
       " 0.057324176941755844,\n",
       " 0.05732417761915968,\n",
       " 0.05732417873656889,\n",
       " 0.05732418057978757,\n",
       " 0.05732418362026278,\n",
       " 0.057324188635668585,\n",
       " 0.05732419690881461,\n",
       " 0.05732421055575528,\n",
       " 0.057324233067021696,\n",
       " 0.05732427020040843,\n",
       " 0.057324331453669025,\n",
       " 0.057324432493798316,\n",
       " 0.057324599164254385,\n",
       " 0.05732487409507941,\n",
       " 0.057325327606659385,\n",
       " 0.057326075696138436,\n",
       " 0.0573273097072699,\n",
       " 0.057329345273362795,\n",
       " 0.057332703054067596,\n",
       " 0.05733824192292991,\n",
       " 0.05734737868946884,\n",
       " 0.05736245060345227,\n",
       " 0.057387313492069596,\n",
       " 0.05742832887401477,\n",
       " 0.05749599348913709,\n",
       " 0.057607630610930195,\n",
       " 0.05779183834974357,\n",
       " 0.05809585056373358,\n",
       " 0.058597738335997164,\n",
       " 0.05942668106249863,\n",
       " 0.06079672156203179,\n",
       " 0.06306298517898123,\n",
       " 0.06681452778533932,\n",
       " 0.07302244809936499,\n",
       " 0.08325143876763427,\n",
       " 0.0998655064556571,\n",
       " 0.12590162468287208,\n",
       " 0.16387184201154342,\n",
       " 0.21311359049242926,\n",
       " 0.26783769438305355,\n",
       " 0.3194588460797616,\n",
       " 0.3616423714956151,\n",
       " 0.3925932901887296,\n",
       " 0.4137099389049055,\n",
       " 0.42746758215023345,\n",
       " 0.4361800070506458,\n",
       " 0.4416030998655357,\n",
       " 0.4449437018799116,\n",
       " 0.4469885587057611,\n",
       " 0.44823549341032165,\n",
       " 0.44899410810607526,\n",
       " 0.44945499161775254,\n",
       " 0.4497347563484956,\n",
       " 0.44990449145293093,\n",
       " 0.45000743880342864,\n",
       " 0.4500698664153231,\n",
       " 0.4501077183943897,\n",
       " 0.4501306677420944,\n",
       " 0.4501445811604834,\n",
       " 0.45015301618359727,\n",
       " 0.45015812984537523,\n",
       " 0.4501612299307623,\n",
       " 0.4501631093031692,\n",
       " 0.45016424863581594,\n",
       " 0.4501649393324366,\n",
       " 0.45016535805230773,\n",
       " 0.4501656118919684,\n",
       " 0.45016576577657685,\n",
       " 0.4501658590656475,\n",
       " 0.4501659156200314,\n",
       " 0.45016594990484077,\n",
       " 0.45016597068922554,\n",
       " 0.4501659832892849,\n",
       " 0.4501659909277837,\n",
       " 0.45016599555844916,\n",
       " 0.45016599836568444,\n",
       " 0.4501660000675065,\n",
       " 0.45016600109919774,\n",
       " 0.45016600172463667,\n",
       " 0.4501660021037947,\n",
       " 0.45016600233365084,\n",
       " 0.45016600247299565,\n",
       " 0.45016600255747047,\n",
       " 0.45016600260868134,\n",
       " 0.45016600263972684,\n",
       " 0.45016600265854734,\n",
       " 0.4501660026699568,\n",
       " 0.4501660026768736,\n",
       " 0.4501660026810668,\n",
       " 0.4501660026836086,\n",
       " 0.4501660026851497,\n",
       " 0.45016600268608403,\n",
       " 0.45016600268665025,\n",
       " 0.4501660026869937,\n",
       " 0.45016600268720186,\n",
       " 0.4501660026873281,\n",
       " 0.4501660026874043,\n",
       " 0.45016600268745066,\n",
       " 0.45016600268747886,\n",
       " 0.45016600268749574,\n",
       " 0.4501660026875063,\n",
       " 0.4501660026875126,\n",
       " 0.4501660026875162,\n",
       " 0.4501660026875186,\n",
       " 0.45016600268752,\n",
       " 0.4501660026875209,\n",
       " 0.45016600268752144,\n",
       " 0.45016600268752177,\n",
       " 0.45016600268752194,\n",
       " 0.45016600268752194,\n",
       " 0.45016600268752194,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.45016600268752216,\n",
       " 0.4501660026875222,\n",
       " 0.4501660026875222,\n",
       " 0.4501660026875223,\n",
       " 0.4501660026875225,\n",
       " 0.45016600268752277,\n",
       " 0.45016600268752305,\n",
       " 0.45016600268752355,\n",
       " 0.4501660026875245,\n",
       " 0.450166002687526,\n",
       " 0.45016600268752843,\n",
       " 0.4501660026875326,\n",
       " 0.4501660026875394,\n",
       " 0.4501660026875506,\n",
       " 0.4501660026875691,\n",
       " 0.4501660026875997,\n",
       " 0.45016600268764995,\n",
       " 0.4501660026877329,\n",
       " 0.4501660026878699,\n",
       " 0.45016600268809576,\n",
       " 0.45016600268846824,\n",
       " 0.45016600268908274,\n",
       " 0.4501660026900965,\n",
       " 0.4501660026917686,\n",
       " 0.45016600269452695,\n",
       " 0.45016600269907686,\n",
       " 0.45016600270658225,\n",
       " 0.4501660027189625,\n",
       " 0.45016600273938445,\n",
       " 0.45016600277307156,\n",
       " 0.4501660028286399,\n",
       " 0.45016600292030234,\n",
       " 0.45016600307150384,\n",
       " 0.450166003320918,\n",
       " 0.45016600373233795,\n",
       " 0.45016600441099475,\n",
       " 0.4501660055304707,\n",
       " 0.4501660073770982,\n",
       " 0.4501660104231968,\n",
       " 0.4501660154478783,\n",
       " 0.4501660237363245,\n",
       " 0.4501660374085024,\n",
       " 0.4501660599613959,\n",
       " 0.4501660971634402,\n",
       " 0.4501661585299318,\n",
       " 0.450166259756779,\n",
       " 0.45016642673506696,\n",
       " 0.45016670217321747,\n",
       " 0.45016715652040923,\n",
       " 0.45016790598488154,\n",
       " 0.4501691422549106,\n",
       " 0.45017118152208013,\n",
       " 0.4501745453396424,\n",
       " 0.45018009398091835,\n",
       " 0.450189246362394,\n",
       " 0.4502043426598849,\n",
       " 0.45022924203303355,\n",
       " 0.4502703074362368,\n",
       " 0.45033802694637237,\n",
       " 0.4504496796191134,\n",
       " 0.4506337095865616,\n",
       " 0.45093687797120574,\n",
       " 0.45143588873664575,\n",
       " 0.45225610303803754,\n",
       " 0.4536011664314703,\n",
       " 0.4557985733319849,\n",
       " 0.4593661605410749,\n",
       " 0.46509964875238236,\n",
       " 0.47416292193702764,\n",
       " 0.4881146758747835,\n",
       " 0.5087143782643465,\n",
       " 0.5372675294291965,\n",
       " 0.5734371976937697,\n",
       " 0.6141982660530446,\n",
       " 0.6543684841022239,\n",
       " 0.6890300165114462,\n",
       " 0.7157279930116559,\n",
       " 0.7346119458461462,\n",
       " 0.7472151520319936,\n",
       " 0.755319147233123,\n",
       " 0.7604111643383471,\n",
       " 0.7635658541940897,\n",
       " 0.7655036411904923,\n",
       " 0.7666877811994707,\n",
       " 0.7674091143271649,\n",
       " 0.7678476877697888,\n",
       " 0.7681140349430312,\n",
       " 0.768275675535811,\n",
       " 0.7683737303405546,\n",
       " 0.7684331973168594,\n",
       " 0.768469256448641,\n",
       " 0.7684911196480215,\n",
       " 0.7685043748800717,\n",
       " 0.7685124109906202,\n",
       " 0.7685172828567366,\n",
       " 0.7685202363722455,\n",
       " 0.7685220268948695,\n",
       " 0.7685231123661497,\n",
       " 0.7685237704112032,\n",
       " 0.7685241693370483,\n",
       " 0.7685244111771214,\n",
       " 0.7685245577872863,\n",
       " 0.7685246466664039,\n",
       " 0.7685247005473587,\n",
       " 0.7685247332114643,\n",
       " 0.7685247530133352,\n",
       " 0.7685247650177681,\n",
       " 0.7685247722951819,\n",
       " 0.7685247767069481,\n",
       " 0.7685247793814807,\n",
       " 0.7685247810028548,\n",
       " 0.7685247819857759,\n",
       " 0.7685247825816494,\n",
       " 0.7685247829428842,\n",
       " 0.7685247831618744,\n",
       " 0.7685247832946324,\n",
       " 0.7685247833751138,\n",
       " 0.7685247834239037,\n",
       " 0.7685247834534815,\n",
       " 0.7685247834714125,\n",
       " 0.7685247834822827,\n",
       " 0.7685247834888723,\n",
       " 0.7685247834928673,\n",
       " 0.7685247834952891,\n",
       " 0.7685247834967575,\n",
       " 0.7685247834976475,\n",
       " 0.7685247834981869,\n",
       " 0.7685247834985142,\n",
       " 0.7685247834987122,\n",
       " 0.7685247834988327,\n",
       " 0.7685247834989056,\n",
       " 0.7685247834989497,\n",
       " 0.7685247834989765,\n",
       " 0.7685247834989928,\n",
       " 0.7685247834990026,\n",
       " 0.7685247834990085,\n",
       " 0.7685247834990121,\n",
       " 0.7685247834990142,\n",
       " 0.7685247834990157,\n",
       " 0.7685247834990164,\n",
       " 0.768524783499017,\n",
       " 0.7685247834990173,\n",
       " 0.7685247834990173,\n",
       " 0.7685247834990174,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990175,\n",
       " 0.7685247834990174,\n",
       " 0.7685247834990173,\n",
       " 0.7685247834990172,\n",
       " 0.7685247834990171,\n",
       " 0.7685247834990167,\n",
       " 0.768524783499016,\n",
       " 0.768524783499015,\n",
       " 0.7685247834990132,\n",
       " 0.7685247834990105,\n",
       " 0.7685247834990058,\n",
       " 0.7685247834989982,\n",
       " 0.7685247834989856,\n",
       " 0.7685247834989649,\n",
       " 0.7685247834989305,\n",
       " 0.7685247834988741,\n",
       " 0.7685247834987808,\n",
       " 0.7685247834986271,\n",
       " 0.7685247834983734,\n",
       " 0.7685247834979549,\n",
       " 0.7685247834972647,\n",
       " 0.7685247834961262,\n",
       " 0.768524783494248,\n",
       " 0.7685247834911499,\n",
       " 0.7685247834860396,\n",
       " 0.7685247834776098,\n",
       " 0.7685247834637045,\n",
       " 0.7685247834407669,\n",
       " 0.7685247834029304,\n",
       " 0.7685247833405172,\n",
       " 0.7685247832375638,\n",
       " 0.7685247830677375,\n",
       " 0.768524782787601,\n",
       " 0.7685247823255027,\n",
       " 0.76852478156325,\n",
       " 0.7685247803058787,\n",
       " 0.7685247782317859,\n",
       " 0.7685247748104732,\n",
       " 0.7685247691668585,\n",
       " 0.7685247598574532,\n",
       " 0.7685247445011558,\n",
       " 0.7685247191702299,\n",
       " 0.7685246773856946,\n",
       " 0.7685246084601781,\n",
       " 0.7685244947643882,\n",
       " 0.7685243072180568,\n",
       " 0.7685239978521198,\n",
       " 0.7685234875398985,\n",
       " 0.7685226457596909,\n",
       " 0.7685212572137908,\n",
       " 0.7685189667692897,\n",
       " 0.7685151886470041,\n",
       " 0.7685089566560739,\n",
       " 0.7684986772351782,\n",
       " 0.7684817223171043,\n",
       " 0.7684537583780353,\n",
       " 0.7684076414086821,\n",
       " 0.7683315988364893,\n",
       " 0.7682062433445435,\n",
       " 0.7679996818416611,\n",
       " 0.7676595418693543,\n",
       " 0.7671000740823221,\n",
       " 0.7661815649493705,\n",
       " 0.7646782175819762,\n",
       " 0.7622300400187527,\n",
       " 0.7582761235118735,\n",
       " 0.75197629644542,\n",
       " 0.7421567320315312,\n",
       " 0.7273775852754746,\n",
       " 0.706305221661437,\n",
       " 0.6785448031012014,\n",
       " 0.6456563062257954]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate values of X from 0 to 1.\n",
    "x_values = np.linspace(0, 1,1000)\n",
    "\n",
    "# Generate values of Y for each X from 0 to 1.\n",
    "def f(x):\n",
    "    return( 0.2 + 0.4*𝑥**2 + 0.3*𝑥 * np.sin(15*𝑥) + 0.05 * np.cos(50*𝑥))\n",
    "    \n",
    "\n",
    "y = f(x_values)\n",
    "\n",
    "[run_network(x) for x in x_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_hat = [run_network(x) for x in x_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot your predicted and observed values.\n",
    "plt.plot(x_values, y, label = 'True')\n",
    "plt.plot(x_values, y_hat, label = 'Predicted')\n",
    "plt.legend()\n",
    "plt.xlim((0,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE.\n",
    "MSE = mean_squared_error(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043559688882052625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_hat, y):\n",
    "    n = len(y_hat)\n",
    "    SE = [(y_hat[i] - y[i])**2 for i in range(n)]\n",
    "    MSE = sum(SE)/n\n",
    "    return MSE\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0435596888820527"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This will vary depending on your values of $h$ - your MSE may differ from others' MSE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 6**: Suppose you wanted to increase the performance of this neural network. How might you go about doing so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** Modify the weights and bias.  More neurons, and more layers, different activation function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 7**: Summarize the Universal Approximation Theorem and show that it explains why neural networks can perform very well. (Don't copy it; use your own words!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** Neural networks permit us to combine several simpler functions, in order to replicate or closely approximate more complex functions.  This does not mean a neural network will exactly model a relationship, but that any complex function that is difficult to map can be broken down into simpler components within a series of neurons within a hidden layer, then combined into an output layer (or another hidden layer before an output layer) and map out an approximation of the true function of a relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
